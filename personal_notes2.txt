PART 1 -----------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
//IMPORTANT!! When cloning an external project inside of an existing project, make sure to go inside of the newly cloned repo and delete the 	existing .git file with the commands:
		git clone <new project>
		cd <new project>
		rm -rf .git // MUST REMOVE .git FILE WHEN CLONING INTO EXISITNG PROJECT!!! 
		npm install
		"npm start" or "npm run dev"

npm create vite@latest folder-name -- --template react



PART 2 - Communicating with server -------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
npx json-server --port 3001 db.json //need to create "db.json" in root dir before running this command
		//NOTE: it is a "NPX" command not "NPM"
npm install axios // always run npm commands in the project root directory (where the package.json file is found); 
		// axios = promises = asynchronous operations //often used with useEffects -> useEffect(execute this, when this changes)
npm install json-server --save-dev //must make a small addition to the scripts part in the package.json file-> "server": "json-server -p 3001 db.json"
		// --save-dev means to install as a devDependency
npm run server //starts the json server. Note: all custom scripts must include "run" (exceptions are the start and test scripts)



PART 3 - Programming a server with NodeJS and Express ------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
npm init //initializes a new Node.js project by creating a package.json file. No other files are created
npm index.js or npm start // create a .js file in the root of the project and add this code to the "script" section in the package.json file as 		//"start": "node index.js". You can replace "start" and "index" with what ever words you like. This is to start the Node server
		// npm start is a custom script that we defined in index.js
npm install express //express is used to help facilitate Node's code to create backend servers
npm update //updates the dependencies of the project
npm install //used when working on the same project but on another computer in order to install up-to-date dependencies. Must be ran in the project's 		root directory
		//running this command will create the "node_modules" directory. Make sure to add this directory to your .gitignore file. You include 		in your file by simply writing "node_modules" in the file (without the quotation marks). You only have to worry about doing when 		creating backend servers with "npm init" and not the front end server with "npm create vite@latest..."
node --watch index.js /* used to automatically restart the backend server when the code changes (must still refresh the browser manually tho). 
		//Add this code to the "script" section in the package.json file as "dev": "node --watch index.js" */
npm run dev //to start your project server in development mode (once you add the above script in the package.json file)
		//Note: that this "npm run dev" in this project is different to "npm run dev" in Parts 1 and 2 where we created the project with
		//"npm create vite@latest"
		//Note: all custom scripts must include "run"

Postman plugin or https://www.postman.com/downloads/  /*you can install Postman VSCode plug-in or download locally, useful for testing backend code*/
		//to make POST requests, you must click on the Body tab > "raw" radio button > set dropdown box to JSON
			> provide a js object in the text box below
		//Note: keys in the js object must be strings (in double quotes)
REST Client VSCode plugin //alternative tool to postman plugin, visit https://fullstackopen.com/en/part3/node_js_and_express for instructions
		//create "requests" directory at root of app > create "get_all_<NAME>.rest" > define request: GET http://localhost:3001/api/notes
			> click on "Send Request"
		//creating a POST request file is a bit more complicated than a GET request file, look up on how to define a POST request file
		//benefit of using REST Client over Postman is that everyone in the development team has access to these file
		//you can also define multiple requests by separating them with "###"
		//NOTE: empty lines in .rest files are NOT ignored when you send the request. As such they can create problems and should avoid using 
			unnecessary empty lines 

npm install morgan //The morgan middleware is a popular HTTP request logger for Node.js and Express applications. When you install it with npm install 		morgan, you can use it to automatically log details about every HTTP request your server receives. It’s especially useful during 		development, debugging, and troubleshooting.
		//NOTE: DON'T USE MORGAN ON YOUR DEPLOYED PROJECT! Logging data can contain sensitive info and can violate privacy law

npm install cors /* install this in your backend repository. This allows your server to accept requests from web pages that are hosted on a different 		domain, protocol, or port than your backend. Implement the cors middleware near the top of index.js */
npm remove cors //used when you don't need cors middleware anymore
		//you can remove the cors middleware after you set up a proxy in the front end in the vite.config.js file

npm run build /* vite command used to create a production build optimized for production, run the command at the root of the FRONTEND directory, then 		you need to copy the newly generated directory "dist" into the root of your BACKEND directory (you can use the command "cp -r 			dist ../../part3" for quick copying) */
//in the backend package.json file include these custom scripts to quickly update the frontend code in dist located in the backend
"build:ui": "rm -rf dist && cd ../frontend && npm run build && cp -r dist ../backend",
"deploy:full": "npm run build:ui && git add . && git commit -m uibuild && git push"
		// modify script relative paths as needed
		// npm run build:ui
		// npm run deploy:full
		// On Windows, npm scripts are executed in cmd.exe as the default shell which does not support bash commands. For the above bash 		commands to work, you can change the default shell to Bash (in the default Git for Windows installation) as follows:
			npm config set script-shell "C:\\Program Files\\git\\bin\\bash.exe"

node --inspect index.js //used to debug your code in the Chrome dev console, you'll need to click on the green node logo that appears in the console

npm install mongoose //using mongoose API instead of MongoDB directly, install this in the backend directory
node mongo.js yourPassword //used to test the temporary MongoDB file created to test our database, replace "yourPassword" with the password you created 		for the database USER you created (not the MongoDB Atlas account password you created). Refer to your mongo.js file to see how this 		file works when you run it in the terminal

npm install dotenv //a more sophisticated way to define environment variables. Need to create a ".env" file at the root of the project to create these 		environment vars

npm run build:ui // custom script, must be inside of the working directory where the package.json file is located, MUST RUN IN GIT BASH TERMINAL?
npm run deploy:full // custom script, must be inside of the working directory where the package.json file is located, MUST RUN IN GIT BASH TERMINAL?

npm install eslint @eslint/js --save-dev // tool used to check for errors in javascript while in development mode
		//install this in the backend
npx eslint --init // needed to initialize the eslint tool, choose these answers: 
		//How would you like to use ESLint? syntax 
		//What type of modules does your project use? commonjs 
		//Which framework does your project use? none 
		//Does your project use TypeScript? javascript
		//Where does your code run? node
		//Would you like to install them now? yes 
		//Which package manager do you want to use? npm 
			//Configuration will then be saved at "eslint.config.mjs". Refer to part3/eslint.config.mjs on how to reformat the file
npm install --save-dev @stylistic/eslint-plugin-js // a plugin that defines a set of code style-related rules
npx eslint index.js // inspects and validates a file like index.js
npm run lint // custom script, refer to part3/package.json for implementation details



PART 4 - Testing Express servers, user administration ------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
npm test // Custom script to test your code (don't need to include "run" as in "npm run test" for this custom script)
		//Custom script is: "test": "node --test" //NOTE: script is updated on Part4b, see code below
		// must have a file named <file_name>.test.js ready (placed inside of a "tests" directory) before you execute command
		// node:test testing library automatically executes test files that end with .test.js 

npm install lodash // The Lodash library is a popular JavaScript utility library that provides a wide range of helpful functions for working with 		arrays, objects, strings, numbers, and more. It simplifies common programming tasks such as:
			// Deep cloning and merging objects
			// Manipulating and searching arrays (e.g., map, filter, find, groupBy, uniq)
			// Debouncing and throttling functions
			// Working with collections and iterables
			// Generating random values
			// String manipulation (e.g., camelCase, kebabCase)
			// Checking data types and values
//on Part4b, changed the scripts on package.json to:
	"start": "cross-env NODE_ENV=production node index.js",
    	"dev": "cross-env NODE_ENV=development node --watch index.js",
    	"test": "cross-env  NODE_ENV=test node --test",

npm install cross-env // this is so the custom scripts we have define above work on Windows computers

npm install --save-dev supertest // enables easy and automated testing of Node.js HTTP servers 
	// It allows you to write tests that make HTTP requests to your server endpoints directly in your test files.
	// It is commonly used with test runners (like Jest, Mocha, or Node’s built-in test module) to verify that your API behaves as expected.

npm test -- tests/<file-name>.test.js // this runs the tests in the specified file
npm test -- --test-only // this only runs the "test.only" functions in your test files (**COMMAND NOT WORKING AS INTENDED FOR SOME REASON**)
npm test -- --test-name-pattern="a specific note is within the returned notes" // used for running tests with a specific name or describe block
	// it can also contain just a part of the name	
	// (**COMMAND NOT WORKING AS INTENDED FOR SOME REASON**)

//DON'T USE THE COMMAND BELOW
npm install express-async-errors // removes the need for having catch statements when working with async methods
	// THE COMMAND ABOVE ONLY WORKS WITH EXPRESS VERSION 4.X. YOU ARE CURRENTLY RUNNING EXPRESS VERSION 5.X
	// You do NOT need express-async-errors because Express 5 has native support for async/await error handling.
	// if you're using Express 5.x, you can safely remove explicit try/catch blocks in your async route handlers, as long as you have a proper 		error-handling middleware in place.

npm install bcrypt // used to generate password hashes (aka encrypting) before saving passwords to the database
npm install bcryptjs // ONLY USE THIS COMMAND IF bcrypt IS GIVING YOU PROBLEMS ON A WINDOWS COMPUTER
	// you can uninstall bcrypt with the command: npm uninstall bcrypt

npm install jsonwebtoken //used to implement user login functionality
	// If the application has multiple interfaces requiring identification, JWT's validation should be separated into its own middleware. An 		existing library like express-jwt could also be used.



PART 5 - Testing React apps --------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
npm install prop-types // enforces props to have a required value

npm install --save-dev vitest jsdom // libraries used for testing React apps
	//jsdom simulates the browser, allowing Vitest to test UI components or DOM logic in a Node environment.
npm install --save-dev @testing-library/react @testing-library/jest-dom
	// @testing-library/react = Render & interact with React components in tests
	// @testing-library/jest-dom = Adds custom DOM matchers for better assertions in Jest
		// after you run both of the above commands, you need to add this custom script -> "test": "vitest run"

npm install --save-dev eslint-plugin-vitest-globals // used to stop Eslint complaining about keywords such as "test" and "expect" in tests
	// must enable the plugin by editing .eslintrc.cjs as follows:
		//module.exports = {
			  env: { 
			    // ...
			    "vitest-globals/env": true
			  },
			  extends: [
			    // ...
			    'plugin:vitest-globals/recommended',
			  ],
			  // ...
			}

npm install --save-dev @testing-library/user-event // used to make simulating user input easier

npm test -- --coverage //The first time you run the command, Vitest will ask you if you want to install the required library @vitest/coverage-v8. 	Install it, and run the command again and you should see a coverage report in the bash terminal
	//NOTE: THIS COMMAND ONLY WORKS ON A BASH TERMINAL
	//Why this command is useful:
		Identifies untested components or props (like conditionally rendered elements)
		Ensures complex logic in hooks/components is exercised
		Encourages writing more complete unit and integration tests
		Helps teams meet coverage thresholds (useful in CI pipelines)
	//When you run this command, a new "coverage" directory (aka HTML report) will be generated which you can view various reports by
		Right-click index.html found inside of the "coverage" directory
		Select "Reveal in File Explorer"
		Double-click index.html to open it in your default browser

// to run individual test files
npx vitest run TestFile.test.jsx
npx vitest run TestFile.test.jsx --reporter=verbose

npm init playwright@latest // for E2E (end to end) testing
	//install this project in its own directory separated from the frontend/backend directories??
	//when installing package answer the questions with the following answers:
		//Do you want to use TypeScript or JavaScript? Javascript
		//Where to put your end-to-end tests? tests
		//Add a GitHub Actions workflow? false
		//Install Playwright browsers (can be done manually via 'npx playwright install')? true
	// If you see this error when installing package "Playwright Host validation warning:", refer to
		https://fullstackopen.com/en/part5/end_to_end_testing_playwright > "Initializing tests" for how to fix issue 

npx playwright show-report // command to show detailed test report, report will be opened in the browser
	// command can be replaced with custom script below

//add these custom scripts in package.json in Playwright directory
	"scripts": {
	    "test": "playwright test",
	    "test:report": "playwright show-report"
	  }
npm test // custom script defined above to run playwright test
npm run test:report // custom script defined above to run and open playwright test in browser

npx playwright test --ui // runs tests via graphical UI 
	//CUSTOM SCRIPT "npm test -- --ui" ONLY WORKS IN BASH TERMINAL

//INCLUDE THIS SCRIPT TO THE BACKEND AND RUN IT TO ENABLE PLAYWRIGHT TESTING
"start:test": "NODE_ENV=test node index.js"

npm test -- --project chromium // this is to run test on a single broswer instead of the default three: chromium, firefox, webkit
	// running tests on all three browers can significantly slow down testing the more tests you have to run
	// COMMAND ONLY WORKS IN GIT BASH TERMINAL

npm test -- -g "test description" // to test a single test
	// an alternative way to test a single test is to replace the function "test" with "test.only"
	// When the test is ready, only can and should be deleted.

npm test -- -g'test description' --debug // If, and when the tests don't pass and you suspect that the fault is in the tests instead of in the code, 	you should run the tests in debug mode.

npm run test -- --trace on // Almost the same as UI mode is use of the Playwright's Trace Viewer. The idea is that a "visual trace" of the tests is 		saved, which can be viewed if necessary after the tests have been completed.
		//If necessary, Trace can be viewed with the command -> npx playwright show-report
		//or with the npm script we defined -> npm run test:report

//UI mode and Trace Viewer also offer the possibility of assisted search for locators. This is done by pressing the double circle on the left side of 	the upper bar, and then by clicking on the desired user interface element. 

npx playwright codegen http://localhost:5173/  //Playwright also includes a test generator that makes it possible to "record" a test through the user 	interface.
	// When the Record mode is on, the test generator "records" the user's interaction in the Playwright inspector, from where it is possible to 	copy the locators and actions to the tests

//Instead of the command line, Playwright can also be used via the VS Code plugin. The plugin offers many convenient features, e.g. use of breakpoints when debugging tests.
//To avoid problem situations and increase understanding, it is definitely worth browsing Playwright's high-quality documentation. The most important sections are listed below:
	//the section about locators gives good hints for finding elements in test
	//section actions tells how it is possible to simulate the interaction with the browser in tests
	//the section about assertions demonstrates the different expectations Playwright offers for testing



PART 6 - Advanced state management -------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
npm install redux // install this inside of a Vite application

npm install --save-dev jest @babel/preset-env @babel/preset-react eslint-plugin-jest
	// jest -> Test runner -> To write and run your tests
	// @babel/preset-env -> Transpile modern JS for compatibility -> Ensures testable code across environments
	// @babel/preset-react -> Transpile JSX syntax -> Required for testing React components
	// eslint-plugin-jest -> Linting rules for Jest -> Enforces best practices in test files
		// once you have these packages installed, create a new file named ".babelrc" with the following content:
			{
			  "presets": [
			    "@babel/preset-env",
			    ["@babel/preset-react", { "runtime": "automatic" }]
			  ]
			}
		// and add the custom script -> "test": "jest"
		// and in the file .eslintrc.cjs inside of the env field add -> "jest/globals": true

npm install --save-dev deep-freeze // used to ensure that the reducer has been correctly defined as an immutable function

npm install react-redux // enables components to access and share the Redux store

npm install @reduxjs/toolkit // This library for example greatly simplifies the configuration of the Redux store and offers a large variety of tools to 	ease state management

npm install @tanstack/react-query // library to store and manage data retrieved from the server



PART 7 - React router, custom hooks, styling app with CSS and webpack --------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
npm install react-router-dom // library for managing navigation in a React application

npm install eslint-plugin-react-hooks --save-dev // an eslint plugin that ensures hooks are used correctly and not inside any conditional statement,	 loops, or nested functions
	// https://www.npmjs.com/package/eslint-plugin-react-hooks  (follow these steps for configuration)

https://prettier.io/docs/install
npm install --save-dev --save-exact prettier // install both your frontend and backend directories
	node --eval "fs.writeFileSync('.prettierrc','{}\n')" // Then create an empty config file to let editors and other tools know you are using 		Prettier
	node --eval "fs.writeFileSync('.prettierignore','# Ignore artifacts:\nbuild\ncoverage\n')" // Next, create a .prettierignore file to let the 		Prettier CLI and editors know which files to not format. Here’s an example 
	npx prettier . --write // Now, format all files with Prettier
	npx prettier . --check // If you have a CI setup, run the following as part of it to make sure that everyone runs Prettier. This avoids merge 		conflicts and other collaboration issues!
		--check is like --write, but only checks that files are already formatted, rather than overwriting them. prettier --write and 			prettier --check are the most common ways to run Prettier.
	If you use ESLint, install eslint-config-prettier (https://github.com/prettier/eslint-config-prettier#installation) to make ESLint and Prettier 		play nice with each other. It turns off all ESLint rules that are unnecessary or might conflict with Prettier. 

npm outdated --depth 0 // check how up-to-date your dependencies are 
npm install -g npm-check-updates //The dependencies can be brought up to date by updating the file package.json. The best way to do that is by using a 	tool called npm-check-updates. This command can be installed globally
	// The file package.json is brought up to date by running the command: ncu -u
	// Then: npm install

// https://docs.npmjs.com/cli/v11/commands/npm-audit
	//these commands can be used to check the security of dependencies. It compares the version numbers of the dependencies in your application to 		a list of the version numbers of dependencies containing known security threats in a centralized error database
npm audit //prints a long list of complaints and suggested fixes
npm audit fix //audit fix does not update dependencies if their major version number has increased. Updating these dependencies could lead to the whole 	application breaking down.
npm audit signatures

// https://github.com/eslint-community/eslint-plugin-security
npm install --save-dev eslint-plugin-security // helps identify potential security hotspots, but finds a lot of false positives which need triage by a 	human 



PART 8 - GraphQL -------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
/* Apollo Client and the applications state:
"In our example, management of the applications state has mostly become the responsibility of Apollo Client. This is quite a typical solution for GraphQL applications. Our example uses the state of the React components only to manage the state of a form and to show error notifications. As a result, it could be that there are no justifiable reasons to use Redux to manage application state when using GraphQL."
*/
npm install @apollo/server graphql //today's leading library for GraphQL servers (install in the backend)
	// when you run the apollo graphql server, it'll take you to the GraphOS Studio Explorer interface if you click on the server's link in the 		terminal. This interface can be used to make queries to the server.

// https://github.com/uuidjs/uuid#readme
npm install uuid // used for generating unique IDs

npm install @apollo/client graphql // Apollo Client is a powerful, flexible, and production-ready GraphQL client for JavaScript applications. It allows 	your frontend to interact with a GraphQL API, manage remote data, and handle caching, errors, and loading states — all in one place

npm install mongoose dotenv // used previously
npm install express cors // used to help configure apollo server to make use of Websockets API

npm install graphql-ws ws @graphql-tools/schema // two packages for adding subscriptions to GraphQL and a Node.js WebSocket library in the backend

npm install graphql-subscriptions // a core utility for enabling real-time GraphQL subscriptions in an app

npm install graphql-ws  // install this in the frontend in order to make subscriptions work on the client side



PART 9 - TypeScript ----------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
npm install --save-dev ts-node typescript //ts-node compiles and executes the specified TypeScript file immediately so that there is no need for a 	separate compilation step
	// NOTE: it is actually advisable not to use ts-node for official projects

npm install express
npm install --save-dev @types/express //installs the TypeScript type definitions (type checking) for the Express.js library.

npm run ts-node file.ts -- -s --someoption
	// ts-node is a custom script -> "ts-node": "ts-node" 
	// file.ts - The TypeScript file you want to execute
	// -- - This is the argument separator. Everything after -- gets passed directly to the underlying command (ts-node)
	// -s --someoption - These are command-line arguments passed to your TypeScript file

// Usually, types for existing packages can be found from the @types organization within npm, and you can add the relevant types to your project by 	installing an npm package with the name of your package with a @types/ prefix. For example:
npm install --save-dev @types/react @types/express @types/lodash @types/jest @types/mongoose
	// and so on and so on. The @types/ are maintained by "Definitely typed" https://github.com/DefinitelyTyped/DefinitelyTyped, a community 		project to maintain types of everything in one place.

npm install --save-dev ts-node-dev // enables auto-reloading in TypeScript files to improve workflow

npm install --save-dev eslint @eslint/js @types/eslint__js typescript typescript-eslint // an additional method to tsconfig.json to restricts 	developers from using the 'any' type
	// need to create the eslint restrictions rules to its own file eslint.config.mjs 
	// for details refer to https://fullstackopen.com/en/part9/first_steps_with_type_script 

npm install --save-dev @stylistic/eslint-plugin // a modern continuation of eslint-config-prettier and built-in ESLint formatting rules

// script below not working as intended!! use this command instead -> npx tsc --init
**npm run tsc -- --init // this will generate a tsconfig.json file. Must add the custom script "tsc": "tsc" first in package.json
	// Note the extra -- before the actual argument! Arguments before -- are interpreted as being for the npm command, while the ones after that 		are meant for the command that is run through the script (i.e. tsc in this case).
	// script above not working as intended!! use this command instead -> npx tsc --init

npm run tsc // creates a production build by running the TypeScript compiler. A new file will get generated once you run this command
	// in your tsconfig.json file, add this compiler option -> "outDir": "./build/"  

npm start // add this custom script -> "start": "node build/index.js"
	
// run these commands if VScode shows type or style related warnings despite the code having been fixed and you have tried to close and open the file 	that is giving you trouble or restarting the editor. Never trust the editor too much!
npm run tsc
npm run lint

npm install zod // Zod is a TypeScript-first validation library. Using Zod, you can define schemas you can use to validate data, from a simple string 	to a complex nested objec
	// https://zod.dev/

npm create vite@latest my-app-name -- --template react-ts // Creates a new React project with typescript?



PART 10 - React Native -------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
//NOTE: you might have to switch to Node version 20 is order to get your scripts in this project to work
npx create-expo-app rate-repository-app --template expo-template-blank@sdk-50 // Uses Expo to create a React Native app
npx expo install react-native-web@~0.19.6 react-dom@18.2.0 @expo/metro-runtime@~3.1.1 // after you've created the project with the previous command, 
	navigate to the created rate-repository-app directory with the terminal and install these dependencies we'll be needing
npm install --save-dev eslint @babel/eslint-parser eslint-plugin-react eslint-plugin-react-native

To run your project, navigate to the directory and run one of the following npm commands:
- cd rate-repository-app
- npm run android
- npm run ios # you need to use macOS to build the iOS project - use the Expo app if you need to do iOS development without a Mac
- npm run web

npm start // NOTE!!!: if this script doesn't work, it is most likely your Node version. In case of problems, switch to version 20

To start emulator manually from VSCode terminal:
	emulator -avd Pixel_9_Pro_XL_API_VanillaIceCream
	npx expo start
	Then press a to launch the app on the Android emulator.
		//Note you can see all the available emulators you have downloaded with -> emulator -list-avds
		// To download other emulators you must do it through Android Studio

npm run lint // need to add this script -> "lint": "eslint ./src/**/*.{js,jsx} App.js --no-error-on-unmatched-pattern"

npx react-devtools // used for debugging
	// can read more about debugging here -> https://reactnative.dev/docs/debugging
		and https://reactnative.dev/docs/react-native-devtools
		and https://docs.expo.dev/debugging/runtime-issues/

npm install react-router-native // Routing used specifically for React Native apps

// https://formik.org/docs/overview
npm install formik 
	// Formik helps you manage forms by handling things like:
		- Form state (values)
		- Validation
		- Error messages
		- Input change handling
		- Form submission
		It's especially helpful for complex forms with lots of inputs, validation rules, and conditional logic.
npm install yup // a validation schema used 

//scripts for React Native backend
"build": "npm run migrate:latest" // this will setup the SQLite database and run the migrations
"seed:run": "knex seed:run" // this will populate the database with some seed data. NOTE: running this command will remove all existing data
"start": "node -r esm ./src/index.js" // after running the top two scripts, run this script

npm install @apollo/client graphql
npm install @expo/metro-config@0.17.4 //Before we can start using Apollo Client, we will need to slightly configure the Metro bundler so that it 	handles the .cjs file extensions used by the Apollo Client
	// you must then add a metro.config.js file in the root directory and then restart the the Expo development tools

npm install expo-constants // provides system and app-level constants about the device and the running app environment. Useful since React Native 	doesn't have direct support for environment variables

npx expo start --clear // If you make changes in configuration, the restart may not be enough. You may need to start the application with cache cleared

npm install dotenv 

npx expo install @react-native-async-storage/async-storage // a React Native library for persistent local storage — it lets you store simple key–value 	pairs on the device, even after the app is closed or restarted

npx expo install expo-secure-store // SecureStore is similar persisted storage as the AsyncStorage but it encrypts the stored data. This makes it more 	suitable for storing more sensitive data such as the user's credit card number.

npm install --save-dev jest jest-expo eslint-plugin-jest // Testing React Native applications
	// must configure frontend's package.json to use jest
		// please refer to https://fullstackopen.com/en/part10/testing_and_extending_our_application  for configuration details

npm install --save-dev --legacy-peer-deps react-test-renderer@18.2.0 @testing-library/react-native @testing-library/jest-native
	// If you face peer dependency issues, make sure that the react-test-renderer version matches the project's React version in the npm install 		command above. You can check the React version by running npm list react --depth=0.
	// If the installation fails due to peer dependency issues, try again using the --legacy-peer-deps flag with the npm install command.

npm install expo-linking // provides utilities for your app to interact with other installed apps using deep links. It also provides helper methods for 	constructing and parsing deep links into your app.
	// if the peer depencendy issues prevent installing the library, try -> npm install expo-linking --legacy-peer-deps

npm install date-fns // date-fns provides the most comprehensive, yet simple and consistent toolset for manipulating JavaScript dates in a browser & 	Node.js

npm install @react-native-picker/picker // a React Native library that provides a cross-platform dropdown (picker/select) UI component, similar to the 	<select> element in HTML.

npm install use-debounce // To avoid a multitude of unnecessary requests while the user types the keyword fast, only pick the latest input after a 	short delay. This technique is often referred to as debouncing



Part 11 - CI/CD --------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
git pull --rebase origin main // The --rebase option tells Git to move all of the developer's commits to the tip of the main branch after synchronising 	it with	the changes from the central repository

git commit -m "Fix typo #skip" // Skips deployment (any commit with #skip triggers skip)
	// please refer to exercise 11.16 on how to set up this #skip trigger
	// https://fullstackopen.com/en/part11/keeping_green

-Use Datadog to keep track of your build time metrics.
ChatGPT Follow Up Question:
"I am going to be building a monolith app using this stack:
Nx, typescript, expo, Jenkins, docker, GraphQL (Apollo Server/ Client), redux toolkit, jest, express, mongoDB/ Mongoose, Redis
Please suggest a short list of metrics observability platforms with pros/ cons. Not sure what the data volume is going to be but i'm going to be making a social media platform where users can upload lots of pictures, short clips, make comments, send DMs, video/ audio calling, and will contain a google maps feature. Budget will be very low as i'm going to build this project myself."



Part 12 - Containers ---------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
// FOR THIS SECTION DOWNLOADED "Docker Desktop" and "WSL" DESKTOP APPLICATIONS

// There are 2 rules of thumb you should follow when creating images:
	- Try to create as secure of an image as possible
	- Try to create as small of an image as possible
// The order of Dockerfile commands also affects its optimization. Make sure the ordering of the commands take advantage of "Docker's layer caching"

docker run --help // to see all the available commands for docker

docker container run IMAGE-NAME // Tells Docker to create a container from an image. A particularly nice feature of the command is that it can run a 	container even if the image to run is not downloaded on our device yet.

docker container run -it ubuntu bash // creates a new docker container

wsl // use this command without any arguments to drop into a WSL shell

// To record the commands you use, use the following commands in order:
script <can-specifily-which-file-to-save-commands-in> // need to include "wsl" before "script" if not in an active WSL shell or a Docker container
<commands to be recorded>
exit
	//output will be saved in a file named "typescript" (no relation to the programming language) if no file is specified in the script command

// alternative workflow to what is shown above:
# Start transcript recording in PowerShell
Start-Transcript -Path "script-answers/exercise12_2.txt"
# Run the Docker command
docker run -it ubuntu bash
# Inside the container, run:
mkdir -p /usr/src/app
echo 'console.log("Hello from Docker container!");' > /usr/src/app/index.js
ls -la /usr/src/app/
exit
# Stop recording
Stop-Transcript

docker container ls // command without -a lists running containers 
docker ps // short version of "docker container ls", lists running containers
docker container ls -a //  list all of the containers, the -a (or --all) will list containers that have already been exited

docker start -i CONTAINER-ID-OR-CONTAINER-NAME // if a container has already exited, we can start it agian with this start command that will accept the 	id or name of the container as a parameter. 
	// -i is shorthand for --interactive

docker kill CONTAINER-ID-OR-CONTAINER-NAME // sends a signal SIGKILL to the process forcing it to exit, and that causes the container to stop.

// Installing Nano text editor inside of a docker container (once you run the command "docker start -i CONTAINER-ID-OR-CONTAINER-NAME")
root@b8548b9faec3:/# apt-get update
root@b8548b9faec3:/# apt-get -y install nano
root@b8548b9faec3:/# nano /usr/src/app/index.js

// Installing Node in a container
docker start -i angry_mccarthy // replace angry_mccarthy with desired container name
apt update
apt install -y curl
curl -sL https://deb.nodesource.com/setup_20.x | bash
apt install -y nodejs
node --version
npm --version
exit // exists container

docker commit CONTAINER-ID-OR-CONTAINER-NAME NEW-IMAGE-NAME // creates a new image from an existing container
	// Why/When You’d Do This
		- Preserve changes made inside a running container
		- Create a custom base image
		- Checkpoint or backup a container state
		- NOTE: IT'S USUALY NOT BEST PRACTICE TO USE "docker commit". USE A dockerfile INSTEAD

docker container diff // to check for the changes between the original image and container

docker image ls // to list your current images

docker container run -it --name hello-node node:20 bash
	// "--name hello-node" this gives your newly created container a custom name
	// "node:20" The image to use: the official Node.js 20 image from Docker Hub (If you don’t have it locally, Docker pulls it)
	// "bash" The command to run inside the container (Instead of running node directly, this drops you into a bash shell inside the Node.js 20 		environment.)

docker container cp ./index.js hello-node:/usr/src/app/index.js
	// "docker container cp" Copy files between your host machine and a Docker container
	// "./index.js" The source file on your host
	// "hello-node:/usr/src/app/index.js" The destination:
		// hello-node = the name (or ID) of your running/stopped container.
		// /usr/src/app/index.js = where inside the container you want the file to go.
	// once you run this command, you can now run "node /usr/src/app/index.js" in the container

docker run node:20 ls // replace "node:20" with desired image. This will list all of the existing directories in the image at the root level

docker build // builds an image based on the Dockerfile
docker build -t fs-hello-world . // replace "fs-hello-world" with any desired name to give to your image
	// "-t" assigns a name (an optionally a version) to the image you're building. "fs-hello-world" is the given name in this example
	// "." (dot) Docker looks in the current directory (.) for a Dockerfile.
		// It uploads that directory (minus .dockerignore exclusions) as the build context.

npx express-generator // creates a basic Express application skeleton

//NOTE: THE COMMAND BELOW IS POWERSHELL SYNTAX! DON'T USE THIS SYNTAX IN DOCKERFILES! MUST USE UNIX SYNTAX
$env:DEBUG="part12-containers-applications:*"; npm start // replace "part12-containers-applications" with actual application directory name
	// "$env:DEBUG="part12-containers-applications:*" sets an environment variable for the current shell session (or for the command after the 		semicolon).
	// "npm start" Node.js will see the environment variable DEBUG and pass it into the app when you run it
//UNIX SYNTAX FOR THE COMMAND ABOVE FOR DOCKERFILES TO BE USED IN THE "CMD" LINE
DEBUG=part12-containers-applications:* npm start

docker run -p 3123:3000 express-server // replace "express-server" with image name
	// The -p flag in the run command will inform Docker that a port from the host machine should be opened and directed to a port in the 			container. 
	// The format is -p host-port:application-port.

npm install // NOTE: use this command during the build process INSIDE a container rather than doing those prior to building.
	// The easy rule of thumb is to only copy files that you would push to GitHub. 
	// Build artifacts or dependencies should not be copied since those can be installed during the build process.
	// this is where ".dockerignore" comes into play

npm ci // Differences between ci and install:
	- install may update the package-lock.json
	- install may install a different version of a dependency if you have ^ or ~ in the version of the dependency.
	- ci will delete the node_modules folder before installing anything
	- ci will follow the package-lock.json and does not alter any files
		// So in short: "ci" creates reliable builds, while "install" is the one to use when you want to install new dependencies.

npm ci --omit=dev // Even better, we can use npm ci --omit=dev to not waste time installing development dependencies.

// Unix syntax of the command below
docker build -t express-server . && docker run -p 3123:3000 express-server
	// Note that we are here chaining two bash commands with &&. We could get (nearly) the same effect by running both commands separately. When 		chaining commands with && if one command fails, the next ones in the chain will not be executed.
// Powershell syntax of the same command above
docker build -t express-server . ; docker run -p 3123:3000 express-server

docker kill <first 2 digits of a container id> // you can kill a running container by using the first 2 digits of its id

// need a docker-compose.yml file in order to use the commands below
// Docker compose lets you define, configure, and run multiple Docker containers as a single application.
// IMPORTANT: When using "docker compose" commands, you don't need to use "docker build" and "docker run" commands
docker compose up // build and run the application
docker compose up --build // If we want to rebuild the images
docker compose up -d // (-d for detached) run the application in the background (you can safely close the terminal if needed without stopping 	container)
docker compose down // close the application and remove containers
docker compose -f docker-compose.dev.yml up // this specifies which Docker Compose file to run
docker compose -f docker-compose.dev.yml up -d // run that file in the background
docker compose -f docker-compose.dev.yml logs -f // to view the output logs. The -f will ensure we follow the logs.

docker compose -f docker-compose.dev.yml down --volumes // --volumes = remove named and anonymous volumes created by that Compose file. (Useful for a 	clean reset, but destructive if you want to keep data.) (-v is shorthand for --volumes)
docker compose -f docker-compose.dev.yml up

docker volume ls // to list the existing volumes
docker volume inspect // inspect of them 
docker volume rm // delete a volume

docker container run -d -p <host_port>:<container_port> <image_name> // -p will publish container’s port to a port of your choosing on your host 	machine. You can find container's port number by running the command "docker container ls"

docker exec -it <container_name_or_id> bash
	//docker exec = Run a command inside an already running container.
	// -it (-i = interactive → keep STDIN open.)(-t = allocate a pseudo-TTY → gives you a terminal interface.)
		Together → makes it feel like you’re “inside” the container.
	// bash = The command to run inside the container. Here → start a Bash shell inside the container.

docker build -f ./dev.Dockerfile -t hello-front-dev . // when you have multiple Dockerfile's in a directory, you need to specify which Dockerfile
	// to build with the '-f' flag

// IMPORTANT: need to run this command below inside of Git Bash for it to work
	// Actually you can replace "pwd" with "PWD" to run the command in Powershell 
docker run -p 5173:5173 -v "$(pwd):/usr/src/app/" hello-front-dev 
	// -v "$(pwd):/usr/src/app/"
	// Mounts a bind volume from your host to the container.
	// $(pwd) → the directory you’re currently in on your machine (in Bash).
	// It’s mounted at /usr/src/app/ inside the container.
	// This means changes to files on your host (e.g., editing code) instantly appear in the container, without rebuilding the image.
docker run -p <host_port>:<container_port> -v <host_path>:<container_path> <image_name> 
	// general form of the command above
	// <host_path> = $(pwd) → the directory you’re currently in on your machine.

docker compose -f docker-compose.dev.yml run debug-helper wget -O - http://app:5173
	// in order to run the command above the Docker compose container must already be running
	// "run debug-helper"
		→ Start a one-off container from the service called debug-helper (defined in that Compose file).
		Unlike up, run is for ad-hoc commands and doesn’t keep the container around unless you specify --rm or -d.
		It runs the container, executes the command you pass, and then exits.
	// "wget -O - http://app:5173"
		→ The command that will be executed inside the debug-helper container:
		wget → fetch a URL (wget is a tool included in the Busybox image to send a request)
		-O - → output to STDOUT instead of saving to a file.
		http://app:5173 → target URL (we are connecting the specified service defined as "app" in the Docker compose file, to port 5173)
		Here "app" is the service name in your Compose file. Docker Compose creates an internal network where services can reach each other by 			service name.
		The port used is the port from which the application is available in that container, also specified in the docker-compose.dev.yml
docker compose -f <compose-file> run <service-name> <command> [args...] // generic version of the command above

// CHATGPT DOCKER COMPOSE COMMANDS CHEATSHEET
COMMON WORKFLOW:
docker compose build // initial stetup, does not start any containers. Equivalent to running docker build for each service.
docker compose up -d // start development. Builds images (if necessary) and starts containers.
docker compose up --build // make changes and restart
docker compose logs app // debug issues
docker compose exec app bash //debug issues
docker compose down // clean stop

BASIC OPERATIONS
docker compose up // build and start all services
docker compose up -d // build and start in background
docker compose up app // build and start specific service ("app" is the service name from your docker-compose.yml (this is an arbitrary given name when 	defining your docker-compose.yml file))
docker compose start // start without rebuilding
docker compose stop // stop all services
docker compose down // stop and remove containers

BUILDING WITH COMPOSE
docker compose build // build all services (but does not run containers)
docker compose build app // build a specific service
docker compose up --build // force rebuild and start
docker compose restart app // restart a specific service

DEVELOPMENT WORKFLOW
docker compose -f docker-compose.dev.yml up // use specific compose file
docker compose logs // view logs
docker compose logs app // view logs for specific service
docker compose log -f app // follow logs in real-time
docker compose exec app bash // execute command in service. Runs a command inside a running container for a given service defined in your docker-	compose.yml.
	// In this case, you’re asking for an interactive Bash shell inside the app container.

CLEAN UP
docker compose down -v // stop and remove everything (containers, networks, volumes) (-v is shorthand for --volumes)



Part 13 - Using relational databases -----------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------

docker run -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 postgres // to run a Postgres database on a docker container locally

// https://www.postgresql.org/docs/current/app-psql.html
	// commands used to access postgres database directly

// "PgAdmin 4" - UI interface for postgres databases

psql -U david -d postgres // connects to postgress database
	// "david" is the user
	// "postgres" is the (default) database

// once you have the postgres docker container running, you can open up its psql console to use commands directly into the docker db
docker exec -it ff3f49eadf27 psql -U postgres postgres
	// replace ff3f49eadf27 with your container ID
docker ps // to find the correct contianer ID

// once connected to the database with the command "docker exec -it ff3f49eadf27 psql -U postgres postgres" you can create a table by pasting something 	like this into the terminal:
CREATE TABLE notes (
    id SERIAL PRIMARY KEY,
    content text NOT NULL,
    important boolean,
    date time
);

// once you have a table created you can view a "list of relations" with this command:
\d



































